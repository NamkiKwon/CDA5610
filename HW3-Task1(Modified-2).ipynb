{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36a7b26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Input file path\n",
    "path = './kmeans_data/'\n",
    "\n",
    "# Input data\n",
    "data = pd.read_csv(path+'data.csv')\n",
    "X = data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "6f230928",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10\n",
    "\n",
    "class KMeans:\n",
    "    def __init__(self, k, distance_function='euclidean', max_iter=100, tol=1e-4):\n",
    "        self.k = k\n",
    "        self.distance_function = distance_function\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "\n",
    "    def euclidean_distance(self, x1, x2):\n",
    "        return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "    def cosine_similarity(self, x1, x2):\n",
    "        dot_product = np.dot(x1, x2)\n",
    "        norm_x1 = np.linalg.norm(x1)\n",
    "        norm_x2 = np.linalg.norm(x2)\n",
    "        cosine_sim = dot_product / (norm_x1 * norm_x2)\n",
    "        return 1 - cosine_sim\n",
    "\n",
    "    def generalized_jaccard_similarity(self, x1, x2):\n",
    "        intersection = np.sum(np.minimum(x1, x2))\n",
    "        union = np.sum(np.maximum(x1, x2))\n",
    "        jaccard_sim = intersection / union\n",
    "        return 1 - jaccard_sim\n",
    "\n",
    "    def initialize_centroids(self, X):\n",
    "        centroids_indices = np.random.choice(X.shape[0], self.k, replace=False)\n",
    "        centroids = X[centroids_indices]\n",
    "        return centroids\n",
    "\n",
    "    def assign_clusters(self, X, centroids):\n",
    "        distances = np.zeros((X.shape[0], self.k))\n",
    "        for i in range(self.k):\n",
    "            if self.distance_function == 'euclidean':\n",
    "                distances[:, i] = np.array([self.euclidean_distance(X[j], centroids[i]) for j in range(X.shape[0])])\n",
    "            elif self.distance_function == 'cosine':\n",
    "                distances[:, i] = np.array([self.cosine_similarity(X[j], centroids[i]) for j in range(X.shape[0])])\n",
    "            elif self.distance_function == 'jaccard':\n",
    "                distances[:, i] = np.array([self.generalized_jaccard_similarity(X[j], centroids[i]) for j in range(X.shape[0])])\n",
    "        cluster_labels = np.argmin(distances, axis=1)\n",
    "        return cluster_labels\n",
    "\n",
    "    def update_centroids(self, X, cluster_labels):\n",
    "        centroids = np.zeros((self.k, X.shape[1]))\n",
    "        for i in range(self.k):\n",
    "            cluster_indices = np.where(cluster_labels == i)\n",
    "            if len(cluster_indices[0]) > 0:\n",
    "                cluster_data = X[cluster_indices]\n",
    "                centroids[i] = np.mean(cluster_data, axis=0)\n",
    "        return centroids\n",
    "\n",
    "    def fit(self, X):\n",
    "        centroids = self.initialize_centroids(X)\n",
    "        for i in range(self.max_iter):\n",
    "            prev_centroids = centroids\n",
    "            cluster_labels = self.assign_clusters(X, centroids)\n",
    "            centroids = self.update_centroids(X, cluster_labels)\n",
    "            if np.sum(np.abs(centroids - prev_centroids)) < self.tol:\n",
    "                break\n",
    "        return cluster_labels, centroids\n",
    "\n",
    "    def plot_clusters(self, X, cluster_labels, centroids):\n",
    "        plt.scatter(X[:, 0], X[:, 1], c=cluster_labels, cmap='viridis')\n",
    "        plt.scatter(centroids[:, 0], centroids[:, 1], c='red', marker='x')\n",
    "        plt.xlabel('X1')\n",
    "        plt.ylabel('X2')\n",
    "        plt.title('K-means Clustering')\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "kmeans = KMeans(k=k, distance_function='euclidean', max_iter=100)\n",
    "\n",
    "# Fit the data\n",
    "#cluster_labels, centroids = kmeans.fit(X)\n",
    "\n",
    "# Plot the clusters and centroids\n",
    "#kmeans.plot_clusters(X, cluster_labels, centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b0157c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of Squared Errors (SSE) for Euclidean-K-means: 25405049878.59018\n",
      "Sum of Squared Errors (SSE) for Cosine-K-means: 25416869026.07649\n",
      "Sum of Squared Errors (SSE) for Jaccard-K-means: 25412506666.600773\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - 1 Kmeans Clustering\n",
    "\n",
    "class KMeans_clustering:\n",
    "    def __init__(self, k, similarity='euclidean', max_iter=100, tol=1e-4):\n",
    "        self.k = k\n",
    "        self.similarity = similarity\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.centroids = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Randomly initialize centroids\n",
    "        centroids = X[np.random.choice(X.shape[0], size=self.k, replace=False)]\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            # Compute similarity between data points and centroids\n",
    "            if self.similarity == 'euclidean':\n",
    "                distances = self.euclidean_distance(X, centroids)\n",
    "            elif self.similarity == 'cosine':\n",
    "                distances = self.cosine_similarity(X, centroids)\n",
    "            elif self.similarity == 'jaccard':\n",
    "                distances = self.jaccard_similarity(X, centroids)\n",
    "            else:\n",
    "                raise ValueError('Invalid similarity metric. Choose from \"euclidean\", \"cosine\", or \"jaccard\".')\n",
    "\n",
    "            # Assign data points to closest centroids\n",
    "            cluster_labels = np.argmin(distances, axis=1)\n",
    "\n",
    "            # Update centroids\n",
    "            new_centroids = np.array([X[cluster_labels == i].mean(axis=0) for i in range(self.k)])\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.linalg.norm(new_centroids - centroids) < self.tol:\n",
    "                break\n",
    "\n",
    "            centroids = new_centroids\n",
    "\n",
    "        self.centroids = centroids\n",
    "        return cluster_labels, centroids\n",
    "\n",
    "    def euclidean_distance(self, X, centroids):\n",
    "        return np.sqrt(np.sum((X[:, np.newaxis] - centroids) ** 2, axis=2))\n",
    "\n",
    "    def cosine_similarity(self, X, centroids):\n",
    "        X_norm = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "        centroids_norm = np.linalg.norm(centroids, axis=1, keepdims=True)\n",
    "        return 1 - np.dot(X, centroids.T) / (X_norm * centroids_norm.T)\n",
    "\n",
    "    def jaccard_similarity(self, X, centroids):\n",
    "        intersection = np.dot(X, centroids.T)\n",
    "        union = np.sum(X, axis=1, keepdims=True) + np.sum(centroids, axis=1) - intersection\n",
    "        return 1 - intersection / union\n",
    "\n",
    "    def sum_of_squared_errors(self, X, cluster_labels, centroids):\n",
    "        return np.sum((X - centroids[cluster_labels]) ** 2)\n",
    "\n",
    "# Generate sample data\n",
    "np.random.seed(42)\n",
    "#X = np.random.rand(100, 2)\n",
    "\n",
    "# Set number of clusters (k) equal to the number of unique categorical values in y\n",
    "y = np.random.randint(0, 3, size=100)  # Example categorical labels\n",
    "k = 10\n",
    "\n",
    "# Initialize and fit K-Means models with different similarity metrics\n",
    "kmeans_euclidean = KMeans_clustering(k=k, similarity='euclidean')\n",
    "cluster_labels_euclidean, centroids_euclidean = kmeans_euclidean.fit(X)\n",
    "sse_euclidean = kmeans_euclidean.sum_of_squared_errors(X, cluster_labels_euclidean, centroids_euclidean)\n",
    "\n",
    "kmeans_cosine = KMeans_clustering(k=k, similarity='cosine')\n",
    "cluster_labels_cosine, centroids_cosine = kmeans_cosine.fit(X)\n",
    "sse_cosine = kmeans_cosine.sum_of_squared_errors(X, cluster_labels_cosine, centroids_cosine)\n",
    "\n",
    "kmeans_jaccard = KMeans_clustering(k=k, similarity='jaccard')\n",
    "cluster_labels_jaccard, centroids_jaccard = kmeans_jaccard.fit(X)\n",
    "sse_jaccard = kmeans_jaccard.sum_of_squared_errors(X, cluster_labels_jaccard, centroids_jaccard)\n",
    "\n",
    "print(\"Sum of Squared Errors (SSE) for Euclidean-K-means:\", sse_euclidean)\n",
    "print(\"Sum of Squared Errors (SSE) for Cosine-K-means:\", sse_cosine)\n",
    "print(\"Sum of Squared Errors (SSE) for Jaccard-K-means:\", sse_jaccard)\n",
    "\n",
    "#if sse_euclidean < sse_cosine and sse_euclidean < sse_jaccard:\n",
    "#    print(\"Euclidean-K-means has the lowest SSE and is the better method.\")\n",
    "#    elif sse_cosine < sse_euclidean and sse_cosine < sse_jaccard:\n",
    "#    print(\"Cosine-K-means has the lowest SSE and is the better method.\")\n",
    "#    else:\n",
    "#    print(\"Jaccard-K-means has the lowest SSE and is the better method.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cc25b44f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Euclidean KMeans clustering:  0.0094\n",
      "Accuracy of Cosine KMeans clustering:  0.0108\n",
      "Accuracy of Jaccard KMeans clustering:  0.009\n",
      "=======================================================\n",
      "Accuracy of Euclidean KMeans clustering: 0.94%\n",
      "Accuracy of Cosine KMeans clustering: 1.08%\n",
      "Accuracy of Jaccard KMeans clustering: 0.90%\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - 2 Compare the accuracies of Euclidean-K-means Cosine-K-means, Jaccard-K-means\n",
    "\n",
    "class KMeans_clustering:\n",
    "    def __init__(self, k, similarity='euclidean', max_iter=100, tol=1e-4):\n",
    "        self.k = k\n",
    "        self.similarity = similarity\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.centroids = None\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Randomly initialize centroids\n",
    "        centroids = X[np.random.choice(X.shape[0], size=self.k, replace=False)]\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            # Compute similarity between data points and centroids\n",
    "            if self.similarity == 'euclidean':\n",
    "                distances = self.euclidean_distance(X, centroids)\n",
    "            elif self.similarity == 'cosine':\n",
    "                distances = self.cosine_similarity(X, centroids)\n",
    "            elif self.similarity == 'jaccard':\n",
    "                distances = self.jaccard_similarity(X, centroids)\n",
    "            else:\n",
    "                raise ValueError('Invalid similarity metric. Choose from \"euclidean\", \"cosine\", or \"jaccard\".')\n",
    "\n",
    "            # Assign data points to closest centroids\n",
    "            cluster_labels = np.argmin(distances, axis=1)\n",
    "\n",
    "            # Update centroids\n",
    "            new_centroids = np.array([X[cluster_labels == i].mean(axis=0) for i in range(self.k)])\n",
    "\n",
    "            # Check for convergence\n",
    "            if np.linalg.norm(new_centroids - centroids) < self.tol:\n",
    "                break\n",
    "\n",
    "            centroids = new_centroids\n",
    "\n",
    "        self.centroids = centroids\n",
    "        return cluster_labels, centroids\n",
    "\n",
    "    def euclidean_distance(self, X, centroids):\n",
    "        return np.sqrt(np.sum((X[:, np.newaxis] - centroids) ** 2, axis=2))\n",
    "\n",
    "    def cosine_similarity(self, X, centroids):\n",
    "        X_norm = np.linalg.norm(X, axis=1, keepdims=True)\n",
    "        centroids_norm = np.linalg.norm(centroids, axis=1, keepdims=True)\n",
    "        return 1 - np.dot(X, centroids.T) / (X_norm * centroids_norm.T)\n",
    "\n",
    "    def jaccard_similarity(self, X, centroids):\n",
    "        intersection = np.dot(X, centroids.T)\n",
    "        union = np.sum(X, axis=1, keepdims=True) + np.sum(centroids, axis=1) - intersection\n",
    "        return 1 - intersection / union\n",
    "\n",
    "    def sum_of_squared_errors(self, X, cluster_labels, centroids):\n",
    "        return np.sum((X - centroids[cluster_labels]) ** 2)\n",
    "\n",
    "    def majority_vote_label(self, X, cluster_labels, y):\n",
    "        majority_vote_labels = []\n",
    "        for i in range(self.k):\n",
    "            cluster_indices = np.where(cluster_labels == i)[0]\n",
    "            #cluster_labels = y[cluster_indices]           \n",
    "            unique_labels, counts = np.unique(cluster_labels, return_counts=True)\n",
    "            majority_vote_label = unique_labels[np.argmax(counts)]\n",
    "            majority_vote_labels.append(majority_vote_label)\n",
    "        return majority_vote_labels\n",
    "    \n",
    "    def compute_predictive_accuracy(self, X, cluster_labels, majority_vote_labels, y):\n",
    "        correct_predictions = 0\n",
    "        for i in range(self.k):\n",
    "            cluster_indices = np.where(cluster_labels == i)[0]\n",
    "            cluster_labels = y[cluster_indices]\n",
    "            correct_predictions += np.sum(cluster_labels == majority_vote_labels[i])\n",
    "        return correct_predictions / len(y)\n",
    "    \n",
    "# Generate sample data\n",
    "#np.random.seed(42)\n",
    "#X = np.random.rand(100, 2)\n",
    "\n",
    "# Set number of clusters (k) equal to the number of unique categorical values in y\n",
    "y = np.random.randint(0, 10, size=10000)  # Example categorical labels\n",
    "k = 10\n",
    "\n",
    "# Initialize and fit KMeans clustering with different similarity metrics\n",
    "kmeans_euclidean = KMeans_clustering(k, similarity='euclidean')\n",
    "kmeans_cosine = KMeans_clustering(k, similarity='cosine')\n",
    "kmeans_jaccard = KMeans_clustering(k, similarity='jaccard')\n",
    "\n",
    "# Fit KMeans clustering with different similarity metrics\n",
    "cluster_labels_euclidean, centroids_euclidean = kmeans_euclidean.fit(X)\n",
    "cluster_labels_cosine, centroids_cosine = kmeans_cosine.fit(X)\n",
    "cluster_labels_jaccard, centroids_jaccard = kmeans_jaccard.fit(X)\n",
    "\n",
    "# Compute the accuracy of the clustering\n",
    "majority_vote_labels_euclidean = kmeans_euclidean.majority_vote_label(X, cluster_labels_euclidean, y)\n",
    "majority_vote_labels_cosine = kmeans_cosine.majority_vote_label(X, cluster_labels_cosine, y)\n",
    "majority_vote_labels_jaccard = kmeans_jaccard.majority_vote_label(X, cluster_labels_jaccard, y)\n",
    "\n",
    "accuracy_euclidean = kmeans_euclidean.compute_predictive_accuracy(X, cluster_labels_euclidean, majority_vote_labels_euclidean, y)\n",
    "accuracy_cosine = kmeans_cosine.compute_predictive_accuracy(X, cluster_labels_cosine, majority_vote_labels_cosine, y)\n",
    "accuracy_jaccard = kmeans_jaccard.compute_predictive_accuracy(X, cluster_labels_jaccard, majority_vote_labels_jaccard, y)\n",
    "\n",
    "print('Accuracy of Euclidean KMeans clustering: ', accuracy_euclidean)\n",
    "print('Accuracy of Cosine KMeans clustering: ', accuracy_cosine)\n",
    "print('Accuracy of Jaccard KMeans clustering: ', accuracy_jaccard)\n",
    "print('=======================================================')\n",
    "print('Accuracy of Euclidean KMeans clustering: {:.2f}%'.format(accuracy_euclidean * 100))\n",
    "print('Accuracy of Cosine KMeans clustering: {:.2f}%'.format(accuracy_cosine * 100))\n",
    "print('Accuracy of Jaccard KMeans clustering: {:.2f}%'.format(accuracy_jaccard * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f7cf2d63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged due to no change in centroid position.\n",
      "Converged due to SSE increase.\n",
      "Converged due to SSE increase.\n",
      "Euclidean-K-means converged in 6 iterations with elapsed time of 0.0837 seconds.\n",
      "Cosine-Kmeans converged in 1 iterations with elapsed time of 0.0279 seconds.\n",
      "Jaccard-K-means converged in 1 iterations with elapsed time of 0.0199 seconds.\n",
      "Euclidean-K-means requires more iterations to converge.\n",
      "Euclidean-K-means takes more time to converge.\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - 3 Set up the same stop criteria: \n",
    "# when there is no change in centroid position OR when the SSE value increases in the next iteration \n",
    "# OR when the maximum preset value (e.g., 500, you can set the preset value by yourself) of iteration is completeâ€\n",
    "\n",
    "import time\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "def cosine_similarity(x1, x2):\n",
    "    dot_product = np.dot(x1, x2)\n",
    "    norm_x1 = np.linalg.norm(x1)\n",
    "    norm_x2 = np.linalg.norm(x2)\n",
    "    return dot_product / (norm_x1 * norm_x2)\n",
    "\n",
    "def jaccard_similarity(x1, x2):\n",
    "    intersection = np.sum(np.minimum(x1, x2))\n",
    "    union = np.sum(np.maximum(x1, x2))\n",
    "    return intersection / union\n",
    "\n",
    "def kmeans(data, k, distance_metric, stop_criteria, max_iterations=500):\n",
    "    n_samples, n_features = data.shape\n",
    "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
    "    iterations = 0\n",
    "    prev_centroids = None\n",
    "    prev_sse = None  # Initialize prev_sse\n",
    "    while iterations < max_iterations:\n",
    "        distances = np.zeros((n_samples, k))\n",
    "        for i in range(k):\n",
    "            if distance_metric == 'euclidean':\n",
    "                distances[:, i] = np.array([euclidean_distance(data[j], centroids[i]) for j in range(n_samples)])\n",
    "            elif distance_metric == 'cosine':\n",
    "                distances[:, i] = np.array([cosine_similarity(data[j], centroids[i]) for j in range(n_samples)])\n",
    "            elif distance_metric == 'jaccard':\n",
    "                distances[:, i] = np.array([jaccard_similarity(data[j], centroids[i]) for j in range(n_samples)])\n",
    "        cluster_assignments = np.argmin(distances, axis=1)\n",
    "        if prev_centroids is not None and np.array_equal(prev_centroids, centroids):\n",
    "            print('Converged due to no change in centroid position.')\n",
    "            break\n",
    "        prev_centroids = np.copy(centroids)\n",
    "        centroids = np.array([np.mean(data[cluster_assignments == i], axis=0) for i in range(k)])\n",
    "        sse = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "        if stop_criteria == 'sse_increase':\n",
    "            if prev_sse is not None and sse > prev_sse:\n",
    "                print('Converged due to SSE increase.')\n",
    "                break\n",
    "            prev_sse = sse\n",
    "        iterations += 1\n",
    "    else:\n",
    "        print('Converged due to reaching maximum iterations.')\n",
    "    return cluster_assignments, centroids, iterations\n",
    "\n",
    "# Example usage\n",
    "#data = np.random.rand(100, 3)  # Generate random data with 100 samples and 3 features\n",
    "k = 10  # Number of clusters\n",
    "max_iterations = 500  # Maximum number of iterations\n",
    "\n",
    "# Perform Euclidean-K-means\n",
    "start_time = time.time()\n",
    "cluster_assignments_euclidean, centroids_euclidean, iterations_euclidean = kmeans(data, k, 'euclidean', 'sse_increase', max_iterations)\n",
    "end_time = time.time()\n",
    "elapsed_time_euclidean = end_time - start_time\n",
    "\n",
    "# Perform Cosine-Kmeans\n",
    "start_time = time.time()\n",
    "cluster_assignments_cosine, centroids_cosine, iterations_cosine = kmeans(data, k, 'cosine', 'sse_increase', max_iterations)\n",
    "end_time = time.time()\n",
    "elapsed_time_cosine = end_time - start_time\n",
    "\n",
    "# Perform Jaccard-K-means\n",
    "start_time = time.time()\n",
    "cluster_assignments_jaccard, centroids_jaccard, iterations_jaccard = kmeans(data, k, 'jaccard', 'sse_increase', max_iterations)\n",
    "end_time = time.time()\n",
    "elapsed_time_jaccard = end_time - start_time\n",
    "\n",
    "print(f\"Euclidean-K-means converged in {iterations_euclidean} iterations with elapsed time of {elapsed_time_euclidean:.4f} seconds.\")\n",
    "print(f\"Cosine-Kmeans converged in {iterations_cosine} iterations with elapsed time of {elapsed_time_cosine:.4f} seconds.\")\n",
    "print(f\"Jaccard-K-means converged in {iterations_jaccard} iterations with elapsed time of {elapsed_time_jaccard:.4f} seconds.\")\n",
    "\n",
    "# Compare which method requires more iterations and time to converge\n",
    "if iterations_euclidean > iterations_cosine and iterations_euclidean > iterations_jaccard:\n",
    "    print(\"Euclidean-K-means requires more iterations to converge.\")\n",
    "elif iterations_cosine > iterations_euclidean and iterations_cosine > iterations_jaccard:\n",
    "    print(\"Cosine-Kmeans requires more iterations to converge.\")\n",
    "elif iterations_jaccard > iterations_euclidean and iterations_jaccard > iterations_cosine:\n",
    "    print(\"Jaccard-K-means requires more iterations to converge.\")\n",
    "else:\n",
    "    print(\"The methods have similar number of iterations to converge.\")\n",
    "\n",
    "if elapsed_time_euclidean > elapsed_time_cosine and elapsed_time_euclidean > elapsed_time_jaccard:\n",
    "    print(\"Euclidean-K-means takes more time to converge.\")\n",
    "elif elapsed_time_cosine > elapsed_time_euclidean and elapsed_time_cosine > elapsed_time_jaccard:\n",
    "    print(\"Cosine-Kmeans takes more time to converge.\")\n",
    "elif elapsed_time_jaccard > elapsed_time_euclidean and elapsed_time_jaccard > elapsed_time_cosine:\n",
    "    print(\"Jaccard-K-means takes more time to converge.\")\n",
    "else:\n",
    "    print(\"The methods have similar convergence time.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "54fb8c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged due to no change in centroid position.\n",
      "Converged due to reaching maximum iterations.\n",
      "Converged due to reaching maximum iterations.\n",
      "Converged due to no change in centroid position.\n",
      "Converged due to SSE increase.\n",
      "Converged due to SSE increase.\n",
      "Converged due to no change in centroid position.\n",
      "Converged due to reaching maximum iterations.\n",
      "Converged due to reaching maximum iterations.\n",
      "SSE for Euclidean K-means with no change in centroid position:  5.79611202532371\n",
      "SSE for Cosine K-means with no change in centroid position:  26.686480235214347\n",
      "SSE for Jaccard K-means with no change in centroid position:  26.686480235214347\n",
      "==============================================================\n",
      "SSE for Euclidean K-means with SSE increase in next iteration:  4.638807074471246\n",
      "SSE for Cosine K-means with SSE increase in next iteration:  26.686480235214347\n",
      "SSE for Jaccard K-means with SSE increase in next iteration:  26.686480235214347\n",
      "==============================================================\n",
      "SSE for Euclidean K-means with maximum preset iterations:  4.924714668648514\n",
      "SSE for Cosine K-means with maximum preset iterations:  26.686480235214347\n",
      "SSE for Jaccard K-means with maximum preset iterations:  26.686480235214347\n"
     ]
    }
   ],
   "source": [
    "# Task 1 - 4 Set up the same stop criteria.\n",
    "# Compare the SSEs of Euclidean-K-means Cosine-K-means, Jaccard-K-means with respect to the following three terminating conditions: (10 points)\n",
    "#  when there is no change in centroid position\n",
    "#  when the SSE value increases in the next iteration\n",
    "#  when the maximum preset value (e.g., 100) of iteration is complete\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "def cosine_similarity(x1, x2):\n",
    "    dot_product = np.dot(x1, x2)\n",
    "    norm_x1 = np.linalg.norm(x1)\n",
    "    norm_x2 = np.linalg.norm(x2)\n",
    "    return dot_product / (norm_x1 * norm_x2)\n",
    "\n",
    "def jaccard_similarity(x1, x2):\n",
    "    intersection = np.sum(np.minimum(x1, x2))\n",
    "    union = np.sum(np.maximum(x1, x2))\n",
    "    return intersection / union\n",
    "\n",
    "def kmeans(data, k, distance_metric, stop_criteria, max_iterations=500):\n",
    "    n_samples, n_features = data.shape\n",
    "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
    "    iterations = 0\n",
    "    prev_centroids = None\n",
    "    prev_sse = None  # Initialize prev_sse\n",
    "    while iterations < max_iterations:\n",
    "        distances = np.zeros((n_samples, k))\n",
    "        for i in range(k):\n",
    "            if distance_metric == 'euclidean':\n",
    "                distances[:, i] = np.array([euclidean_distance(data[j], centroids[i]) for j in range(n_samples)])\n",
    "            elif distance_metric == 'cosine':\n",
    "                distances[:, i] = np.array([cosine_similarity(data[j], centroids[i]) for j in range(n_samples)])\n",
    "            elif distance_metric == 'jaccard':\n",
    "                distances[:, i] = np.array([jaccard_similarity(data[j], centroids[i]) for j in range(n_samples)])\n",
    "        cluster_assignments = np.argmin(distances, axis=1)\n",
    "        if prev_centroids is not None and np.array_equal(prev_centroids, centroids):\n",
    "            print('Converged due to no change in centroid position.')\n",
    "            break\n",
    "        prev_centroids = np.copy(centroids)\n",
    "        centroids = np.array([np.mean(data[cluster_assignments == i], axis=0) for i in range(k)])\n",
    "        sse = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "        if stop_criteria == 'sse_increase':\n",
    "            if prev_sse is not None and sse > prev_sse:\n",
    "                print('Converged due to SSE increase.')\n",
    "                break\n",
    "            prev_sse = sse\n",
    "        iterations += 1\n",
    "    else:\n",
    "        print('Converged due to reaching maximum iterations.')\n",
    "    return cluster_assignments, centroids, iterations\n",
    "\n",
    "k = 10\n",
    "max_iterations = 100\n",
    "\n",
    "# Stop criteria 1: No change in centroid position\n",
    "distance_metric = 'euclidean'\n",
    "cluster_assignments, centroids, iterations = kmeans(data, k, distance_metric, stop_criteria='no_change', max_iterations=max_iterations)\n",
    "sse_euclidean_no_change = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'cosine'\n",
    "cluster_assignments, centroids, iterations = kmeans(data, k, distance_metric, stop_criteria='no_change', max_iterations=max_iterations)\n",
    "sse_cosine_no_change = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'jaccard'\n",
    "cluster_assignments, centroids, iterations = kmeans(data, k, distance_metric, stop_criteria='no_change', max_iterations=max_iterations)\n",
    "sse_jaccard_no_change = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "# Stop criteria 2: SSE increase in next iteration\n",
    "distance_metric = 'euclidean'\n",
    "cluster_assignments, centroids, iterations = kmeans(data, k, distance_metric, stop_criteria='sse_increase', max_iterations=max_iterations)\n",
    "sse_euclidean_sse_increase = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'cosine'\n",
    "cluster_assignments, centroids, iterations = kmeans(data, k, distance_metric, stop_criteria='sse_increase', max_iterations=max_iterations)\n",
    "sse_cosine_sse_increase = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'jaccard'\n",
    "cluster_assignments, centroids, iterations = kmeans(data, k, distance_metric, stop_criteria='sse_increase', max_iterations=max_iterations)\n",
    "sse_jaccard_sse_increase = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "# Stop criteria 3: Maximum preset iterations\n",
    "distance_metric = 'euclidean'\n",
    "cluster_assignments, centroids, iterations = kmeans(data, k, distance_metric, stop_criteria='max_iterations', max_iterations=max_iterations)\n",
    "sse_euclidean_max_iterations = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'cosine'\n",
    "cluster_assignments, centroids, iterations = kmeans(data, k, distance_metric, stop_criteria='max_iterations', max_iterations=max_iterations)\n",
    "sse_cosine_max_iterations = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'jaccard'\n",
    "cluster_assignments, centroids, iterations = kmeans(data, k, distance_metric, stop_criteria='max_iterations', max_iterations=max_iterations)\n",
    "sse_jaccard_max_iterations = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "# Print SSE results\n",
    "print(\"SSE for Euclidean K-means with no change in centroid position: \", sse_euclidean_no_change)\n",
    "print(\"SSE for Cosine K-means with no change in centroid position: \", sse_cosine_no_change)\n",
    "print(\"SSE for Jaccard K-means with no change in centroid position: \", sse_jaccard_no_change)\n",
    "print(\"==============================================================\")\n",
    "print(\"SSE for Euclidean K-means with SSE increase in next iteration: \", sse_euclidean_sse_increase)\n",
    "print(\"SSE for Cosine K-means with SSE increase in next iteration: \", sse_cosine_sse_increase)\n",
    "print(\"SSE for Jaccard K-means with SSE increase in next iteration: \", sse_jaccard_sse_increase)\n",
    "print(\"==============================================================\")\n",
    "print(\"SSE for Euclidean K-means with maximum preset iterations: \", sse_euclidean_max_iterations)\n",
    "print(\"SSE for Cosine K-means with maximum preset iterations: \", sse_cosine_max_iterations)\n",
    "print(\"SSE for Jaccard K-means with maximum preset iterations: \", sse_jaccard_max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2de3cc5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged due to no change in centroid position.\n",
      "Converged due to SSE increase.\n",
      "Converged due to SSE increase.\n",
      "Converged due to reaching maximum iterations.\n",
      "Converged due to reaching maximum iterations.\n",
      "Converged due to reaching maximum iterations.\n",
      "SSE for Euclidean K-means with no change in centroid position:  5.174175631895551\n",
      "SSE for Cosine K-means with no change in centroid position:  26.686480235214347\n",
      "SSE for Jaccard K-means with no change in centroid position:  26.686480235214347\n",
      "==============================================================\n",
      "SSE for Euclidean K-means with SSE increase in next iteration:  5.281121840725107\n",
      "SSE for Cosine K-means with SSE increase in next iteration:  26.686480235214347\n",
      "SSE for Jaccard K-means with SSE increase in next iteration:  26.686480235214347\n",
      "==============================================================\n",
      "SSE for Euclidean K-means with maximum preset iterations:  4.886735237015621\n",
      "SSE for Cosine K-means with maximum preset iterations:  26.686480235214347\n",
      "SSE for Jaccard K-means with maximum preset iterations:  26.686480235214347\n"
     ]
    }
   ],
   "source": [
    "# Version 2 ###Task 1 - 4 Set up the same stop criteria.\n",
    "# Compare the SSEs of Euclidean-K-means Cosine-K-means, Jaccard-K-means with respect to the following three terminating conditions: (10 points)\n",
    "#  when there is no change in centroid position\n",
    "#  when the SSE value increases in the next iteration\n",
    "#  when the maximum preset value (e.g., 100) of iteration is complete\n",
    "\n",
    "\n",
    "k = 10\n",
    "max_iterations = 100\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    return np.sqrt(np.sum((x1 - x2) ** 2))\n",
    "\n",
    "def cosine_similarity(x1, x2):\n",
    "    dot_product = np.dot(x1, x2)\n",
    "    norm_x1 = np.linalg.norm(x1)\n",
    "    norm_x2 = np.linalg.norm(x2)\n",
    "    return dot_product / (norm_x1 * norm_x2)\n",
    "\n",
    "def jaccard_similarity(x1, x2):\n",
    "    intersection = np.sum(np.minimum(x1, x2))\n",
    "    union = np.sum(np.maximum(x1, x2))\n",
    "    return intersection / union\n",
    "\n",
    "def kmeans1(data, k, distance_metric, stop_criteria, max_iterations=500):\n",
    "    n_samples, n_features = data.shape\n",
    "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
    "    iterations = 0\n",
    "    prev_centroids = None\n",
    "    prev_sse = None  # Initialize prev_sse\n",
    "    while iterations < max_iterations:\n",
    "        distances = np.zeros((n_samples, k))\n",
    "        for i in range(k):\n",
    "            if distance_metric == 'euclidean':\n",
    "                distances[:, i] = np.array([euclidean_distance(data[j], centroids[i]) for j in range(n_samples)])\n",
    "            elif distance_metric == 'cosine':\n",
    "                distances[:, i] = np.array([cosine_similarity(data[j], centroids[i]) for j in range(n_samples)])\n",
    "            elif distance_metric == 'jaccard':\n",
    "                distances[:, i] = np.array([jaccard_similarity(data[j], centroids[i]) for j in range(n_samples)])\n",
    "        cluster_assignments = np.argmin(distances, axis=1)\n",
    "        if prev_centroids is not None and np.array_equal(prev_centroids, centroids):\n",
    "            print('Converged due to no change in centroid position.')\n",
    "            break\n",
    "        prev_centroids = np.copy(centroids)\n",
    "        centroids = np.array([np.mean(data[cluster_assignments == i], axis=0) for i in range(k)])\n",
    "#        sse = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "#        if stop_criteria == 'sse_increase':\n",
    "#            if prev_sse is not None and sse > prev_sse:\n",
    "#                print('Converged due to SSE increase.')\n",
    "#                break\n",
    "#            prev_sse = sse\n",
    "        iterations += 1\n",
    "#    else:\n",
    "#        print('Converged due to reaching maximum iterations.')\n",
    "    return cluster_assignments, centroids, iterations\n",
    "\n",
    "def kmeans2(data, k, distance_metric, stop_criteria, max_iterations=500):\n",
    "    n_samples, n_features = data.shape\n",
    "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
    "    iterations = 0\n",
    "    prev_centroids = None\n",
    "    prev_sse = None  # Initialize prev_sse\n",
    "    while iterations < max_iterations:\n",
    "        distances = np.zeros((n_samples, k))\n",
    "        for i in range(k):\n",
    "            if distance_metric == 'euclidean':\n",
    "                distances[:, i] = np.array([euclidean_distance(data[j], centroids[i]) for j in range(n_samples)])\n",
    "            elif distance_metric == 'cosine':\n",
    "                distances[:, i] = np.array([cosine_similarity(data[j], centroids[i]) for j in range(n_samples)])\n",
    "            elif distance_metric == 'jaccard':\n",
    "                distances[:, i] = np.array([jaccard_similarity(data[j], centroids[i]) for j in range(n_samples)])\n",
    "        cluster_assignments = np.argmin(distances, axis=1)\n",
    "#        if prev_centroids is not None and np.array_equal(prev_centroids, centroids):\n",
    "#            print('Converged due to no change in centroid position.')\n",
    "#            break\n",
    "        prev_centroids = np.copy(centroids)\n",
    "        centroids = np.array([np.mean(data[cluster_assignments == i], axis=0) for i in range(k)])\n",
    "        sse = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "        if stop_criteria == 'sse_increase':\n",
    "            if prev_sse is not None and sse > prev_sse:\n",
    "                print('Converged due to SSE increase.')\n",
    "                break\n",
    "            prev_sse = sse\n",
    "        iterations += 1\n",
    "#    else:\n",
    "#        print('Converged due to reaching maximum iterations.')\n",
    "    return cluster_assignments, centroids, iterations\n",
    "\n",
    "\n",
    "def kmeans3(data, k, distance_metric, stop_criteria, max_iterations=500):\n",
    "    n_samples, n_features = data.shape\n",
    "    centroids = data[np.random.choice(n_samples, k, replace=False)]\n",
    "    iterations = 0\n",
    "    prev_centroids = None\n",
    "    prev_sse = None  # Initialize prev_sse\n",
    "    while iterations < max_iterations:\n",
    "        distances = np.zeros((n_samples, k))\n",
    "        for i in range(k):\n",
    "            if distance_metric == 'euclidean':\n",
    "                distances[:, i] = np.array([euclidean_distance(data[j], centroids[i]) for j in range(n_samples)])\n",
    "            elif distance_metric == 'cosine':\n",
    "                distances[:, i] = np.array([cosine_similarity(data[j], centroids[i]) for j in range(n_samples)])\n",
    "            elif distance_metric == 'jaccard':\n",
    "                distances[:, i] = np.array([jaccard_similarity(data[j], centroids[i]) for j in range(n_samples)])\n",
    "        cluster_assignments = np.argmin(distances, axis=1)\n",
    " #       if prev_centroids is not None and np.array_equal(prev_centroids, centroids):\n",
    "#            print('Converged due to no change in centroid position.')\n",
    "#            break\n",
    "        prev_centroids = np.copy(centroids)\n",
    "        centroids = np.array([np.mean(data[cluster_assignments == i], axis=0) for i in range(k)])\n",
    " #       sse = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "#        if stop_criteria == 'sse_increase':\n",
    "#            if prev_sse is not None and sse > prev_sse:\n",
    "#                print('Converged due to SSE increase.')\n",
    "#                break\n",
    "#            prev_sse = sse\n",
    "        iterations += 1\n",
    "    else:\n",
    "        print('Converged due to reaching maximum iterations.')\n",
    "    return cluster_assignments, centroids, iterations\n",
    "\n",
    "\n",
    "k = 10\n",
    "max_iterations = 100\n",
    "\n",
    "# Stop criteria 1: No change in centroid position\n",
    "distance_metric = 'euclidean'\n",
    "cluster_assignments, centroids, iterations = kmeans1(data, k, distance_metric, stop_criteria='no_change', max_iterations=max_iterations)\n",
    "sse_euclidean_no_change = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'cosine'\n",
    "cluster_assignments, centroids, iterations = kmeans1(data, k, distance_metric, stop_criteria='no_change', max_iterations=max_iterations)\n",
    "sse_cosine_no_change = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'jaccard'\n",
    "cluster_assignments, centroids, iterations = kmeans1(data, k, distance_metric, stop_criteria='no_change', max_iterations=max_iterations)\n",
    "sse_jaccard_no_change = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "# Stop criteria 2: SSE increase in next iteration\n",
    "distance_metric = 'euclidean'\n",
    "cluster_assignments, centroids, iterations = kmeans2(data, k, distance_metric, stop_criteria='sse_increase', max_iterations=max_iterations)\n",
    "sse_euclidean_sse_increase = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'cosine'\n",
    "cluster_assignments, centroids, iterations = kmeans2(data, k, distance_metric, stop_criteria='sse_increase', max_iterations=max_iterations)\n",
    "sse_cosine_sse_increase = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'jaccard'\n",
    "cluster_assignments, centroids, iterations = kmeans2(data, k, distance_metric, stop_criteria='sse_increase', max_iterations=max_iterations)\n",
    "sse_jaccard_sse_increase = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "# Stop criteria 3: Maximum preset iterations\n",
    "distance_metric = 'euclidean'\n",
    "cluster_assignments, centroids, iterations = kmeans3(data, k, distance_metric, stop_criteria='max_iterations', max_iterations=max_iterations)\n",
    "sse_euclidean_max_iterations = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'cosine'\n",
    "cluster_assignments, centroids, iterations = kmeans3(data, k, distance_metric, stop_criteria='max_iterations', max_iterations=max_iterations)\n",
    "sse_cosine_max_iterations = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "distance_metric = 'jaccard'\n",
    "cluster_assignments, centroids, iterations = kmeans3(data, k, distance_metric, stop_criteria='max_iterations', max_iterations=max_iterations)\n",
    "sse_jaccard_max_iterations = np.sum([np.sum((data[cluster_assignments == i] - centroids[i]) ** 2) for i in range(k)])\n",
    "\n",
    "# Print SSE results\n",
    "print(\"SSE for Euclidean K-means with no change in centroid position: \", sse_euclidean_no_change)\n",
    "print(\"SSE for Cosine K-means with no change in centroid position: \", sse_cosine_no_change)\n",
    "print(\"SSE for Jaccard K-means with no change in centroid position: \", sse_jaccard_no_change)\n",
    "print(\"==============================================================\")\n",
    "print(\"SSE for Euclidean K-means with SSE increase in next iteration: \", sse_euclidean_sse_increase)\n",
    "print(\"SSE for Cosine K-means with SSE increase in next iteration: \", sse_cosine_sse_increase)\n",
    "print(\"SSE for Jaccard K-means with SSE increase in next iteration: \", sse_jaccard_sse_increase)\n",
    "print(\"==============================================================\")\n",
    "print(\"SSE for Euclidean K-means with maximum preset iterations: \", sse_euclidean_max_iterations)\n",
    "print(\"SSE for Cosine K-means with maximum preset iterations: \", sse_cosine_max_iterations)\n",
    "print(\"SSE for Jaccard K-means with maximum preset iterations: \", sse_jaccard_max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1f0db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
